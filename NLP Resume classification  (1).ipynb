{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c88add84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\sathv\\anaconda3\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (1.10.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (8.1.9)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sathv\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfbb3984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "389e5d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Resume.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14ac6030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resumes</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naveen Sadhu\\n\\n\\n\\n\\n\\nTitle: software develo...</td>\n",
       "      <td>React JS Developer Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ui-Developer/ React JS Developer \\n\\nNAME: KRI...</td>\n",
       "      <td>React JS Developer Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUSOVAN  BAG   \\n\\nSeeking  a  challenging  po...</td>\n",
       "      <td>React JS Developer Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHAIK ABDUL SHARUK   \\n\\n2 years’ Experience i...</td>\n",
       "      <td>React JS Developer Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MD KHIZARUDDIN RAUF \\n\\n \\t EXPERIENCE \\n\\n   ...</td>\n",
       "      <td>React JS Developer Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>\\n  [pic]\\n  [pic]\\n\\n    • 3.3 years of IT ex...</td>\n",
       "      <td>Workday resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>JYOTI VERMA\\t\\t\\t\\t\\t\\n\\n\\n\\nPROFESSIONAL SUMM...</td>\n",
       "      <td>Workday resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>G Himaja\\n\\n                                  ...</td>\n",
       "      <td>Workday resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>\\nName  : Naresh Babu Cherukuri\\n\\n\\nObjective...</td>\n",
       "      <td>Workday resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>\\n                               Hari Krishna ...</td>\n",
       "      <td>Workday resume</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Resumes  \\\n",
       "0   Naveen Sadhu\\n\\n\\n\\n\\n\\nTitle: software develo...   \n",
       "1   Ui-Developer/ React JS Developer \\n\\nNAME: KRI...   \n",
       "2   SUSOVAN  BAG   \\n\\nSeeking  a  challenging  po...   \n",
       "3   SHAIK ABDUL SHARUK   \\n\\n2 years’ Experience i...   \n",
       "4   MD KHIZARUDDIN RAUF \\n\\n \\t EXPERIENCE \\n\\n   ...   \n",
       "..                                                ...   \n",
       "74  \\n  [pic]\\n  [pic]\\n\\n    • 3.3 years of IT ex...   \n",
       "75  JYOTI VERMA\\t\\t\\t\\t\\t\\n\\n\\n\\nPROFESSIONAL SUMM...   \n",
       "76  G Himaja\\n\\n                                  ...   \n",
       "77  \\nName  : Naresh Babu Cherukuri\\n\\n\\nObjective...   \n",
       "78  \\n                               Hari Krishna ...   \n",
       "\n",
       "                     Category  \n",
       "0   React JS Developer Resume  \n",
       "1   React JS Developer Resume  \n",
       "2   React JS Developer Resume  \n",
       "3   React JS Developer Resume  \n",
       "4   React JS Developer Resume  \n",
       "..                        ...  \n",
       "74             Workday resume  \n",
       "75             Workday resume  \n",
       "76             Workday resume  \n",
       "77             Workday resume  \n",
       "78             Workday resume  \n",
       "\n",
       "[79 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb543ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79 entries, 0 to 78\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Resumes   79 non-null     object\n",
      " 1   Category  79 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be33ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resumes</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Resumes  Category\n",
       "0     False     False\n",
       "1     False     False\n",
       "2     False     False\n",
       "3     False     False\n",
       "4     False     False\n",
       "..      ...       ...\n",
       "74    False     False\n",
       "75    False     False\n",
       "76    False     False\n",
       "77    False     False\n",
       "78    False     False\n",
       "\n",
       "[79 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e62c17a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resumes     0\n",
       "Category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f1e41cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fa5dc1",
   "metadata": {},
   "source": [
    "# Checking unnecessary words in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f21e0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    72\n",
       "True      7\n",
       "Name: Resumes, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Resumes.str.contains('https://').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46368ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.911392\n",
       "True     0.088608\n",
       "Name: Resumes, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Resumes.str.contains('https://').value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d110fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    76\n",
       "True      3\n",
       "Name: Resumes, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Resumes.str.contains('@').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c50559f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.962025\n",
       "True     0.037975\n",
       "Name: Resumes, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Resumes.str.contains('@').value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef7fa350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Resumes this period: 79\n"
     ]
    }
   ],
   "source": [
    "print('Total Resumes this period:', len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e52d8a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10054] An\n",
      "[nltk_data]     existing connection was forcibly closed by the remote\n",
      "[nltk_data]     host>\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\sathv/nltk_data'\n    - 'C:\\\\Users\\\\sathv\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\sathv\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\sathv\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\sathv\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[1;32m----> 4\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mResumes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_tokenize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4237\u001b[0m, in \u001b[0;36mSeries.map\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   4162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg, na_action\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m   4163\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4164\u001b[0m \u001b[38;5;124;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[0;32m   4165\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4235\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[0;32m   4236\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4239\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4240\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py:880\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m    877\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# mapper is a function\u001b[39;00m\n\u001b[1;32m--> 880\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mmap_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_values\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    132\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:750\u001b[0m, in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m \u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mopen()\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\sathv/nltk_data'\n    - 'C:\\\\Users\\\\sathv\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\sathv\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\sathv\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\sathv\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "tokens = df['Resumes'].map(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a01e4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc68903",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [Text.strip() for Text in df.Resumes] # removes the given charecters from the beginning and the end of the original string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e33d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e36d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [Text for Text in data if Text] # removes empty strings, because they are considered in python as false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d2ab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbabc764",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "review_text = ' '.join(data) # takes all items in a iterable and joins them into one string.\n",
    "review_text[0:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6476a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "ttr = TweetTokenizer(strip_handles= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2994dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_tokens = ttr.tokenize(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28af4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review_tokens[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677a30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_tokens_text = ' '.join(review_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbcedb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "review_tokens_text[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2857ad57",
   "metadata": {},
   "source": [
    "# Remove Punchuation From Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e45f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c3d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removeing all the punchuation from the review_tokens_text\n",
    "no_punc_text= review_tokens_text.translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7102e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_punc_text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5498496",
   "metadata": {},
   "source": [
    "# Remove URL'S from text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3b59e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_url_text = re.sub(r'http\\s+','',no_punc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec77ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_url_text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4821fa",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536be32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "from nltk.tokenize import word_tokenize\n",
    "text_tokens = word_tokenize(no_url_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32d55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_tokens[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df76403",
   "metadata": {},
   "source": [
    "# Stopwords Removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f921f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011eceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5313deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34168828",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "no_stop_tokens = [word for word in text_tokens if not word in stop_words]\n",
    "print(no_stop_tokens[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a423e3",
   "metadata": {},
   "source": [
    "# Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c2b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_words = [Text.lower() for Text in no_stop_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05c0804",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lower_words[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc3a44",
   "metadata": {},
   "source": [
    "# Applying Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ef109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "stemmed_tokens = [ps.stem(word) for word in lower_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f8f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stemmed_tokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c3e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dde9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3923b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(' '.join(lower_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491df066",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d17a640",
   "metadata": {},
   "source": [
    "# Applying Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a0380",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9769c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e812b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_review = ' '.join(lemmas)\n",
    "print(clean_review[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54c5409",
   "metadata": {},
   "source": [
    "# Text Processing On DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea765ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Resume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a77356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(text, pattern_regex):\n",
    "    r = re.findall(pattern_regex, text)\n",
    "    for i in r:\n",
    "        text = re.sub(i, '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786eccc0",
   "metadata": {},
   "source": [
    "# Converting into Clean Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d94652",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_Resumes'] = np.vectorize(remove_pattern)(df['Resumes'], '@[\\w]*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1df33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfd4fed",
   "metadata": {},
   "source": [
    "# Remove Url from Clean_Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46fea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_Resumes =[]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    words_without_links = [word for word in row.Clean_Resumes.split() if 'http' not in word]\n",
    "    clean_Resumes.append(' '.join(words_without_links)) \n",
    "    \n",
    "df['Clean_Resumes'] = clean_Resumes\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47d5fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Clean_Resumes']!= '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec2f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b17f2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b5f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['Clean_Resumes'],keep = False) # dropping the duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceaf4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81319274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.reset_index(drop=True) # resetting the index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f59d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8372321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb7e51",
   "metadata": {},
   "source": [
    "# Making text lowercase, removing text in square brackets, links, punctuation and remove words containing numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965ebc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('!','', text)\n",
    "    text = re.sub('\\[.*?\\]','', text)\n",
    "    text = re.sub('⇨','',text)\n",
    "    text = re.sub('','',text)\n",
    "    text = re.sub(':','', text)\n",
    "    text = re.sub('•', '', text)\n",
    "    text = re.sub('https?://\\S+|www.\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a251c0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Clean_Resumes = df.Clean_Resumes.apply(lambda x: clean_text(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7dbc66",
   "metadata": {},
   "source": [
    "# Removing emojis from Clean Resumes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4138b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16cfce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Clean_Resumes = df.Clean_Resumes.apply(lambda x: remove_emoji(x))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eedd874",
   "metadata": {},
   "source": [
    "# Removing stop words from Clean_Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4222c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words = stopwords.words('english')\n",
    "\n",
    "cleaned_resumes = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    words_without_stopwords = [word for word in row.Clean_Resumes.split() if word not in my_stop_words]\n",
    "    cleaned_resumes.append(' '.join(words_without_stopwords))\n",
    "    \n",
    "df['Absolute_Clean_Resumes'] = cleaned_resumes\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe4ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859db132",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokenized_Resume = df['Absolute_Clean_Resumes'].apply(lambda x: x.split())\n",
    "Tokenized_Resume.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe3115d",
   "metadata": {},
   "source": [
    "# Applying Lemmatization on Abosulte_Clean_Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7533ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "Tokenized_Resume = Tokenized_Resume.apply(lambda x: [word_lemmatizer.lemmatize(i) for i in x])\n",
    "Tokenized_Resume.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1632d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tokens in enumerate(Tokenized_Resume):\n",
    "    Tokenized_Resume[i] = ' '.join(tokens)\n",
    "    \n",
    "df['Absolute_Clean_Resumes'] = Tokenized_Resume\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d7763e",
   "metadata": {},
   "source": [
    "# Applying count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790771dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "review_cv = cv.fit_transform(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fc89e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254c0cc2",
   "metadata": {},
   "source": [
    "# Applying count Vectorizer on NGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d27b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ngram_range = CountVectorizer(analyzer='word',ngram_range=(1,3), max_features=4000)\n",
    "bow_matrix_ngram = cv_ngram_range.fit_transform(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5dd5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_ngram_range)\n",
    "print(bow_matrix_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e0a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Resumes','Clean_Resumes'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d04ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de34e758",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneSetofStopWords = set(stopwords.words('english')+['``',\"''\"])\n",
    "totalWords = []\n",
    "Sentences = df['Absolute_Clean_Resumes'].values\n",
    "CleanedSentences = \"\"\n",
    "for records in Sentences:\n",
    "    CleanedSentences += records\n",
    "    required_words = nltk.word_tokenize(records)\n",
    "    for word in required_words:\n",
    "        if word not in oneSetofStopWords and word not in string.punctuation:\n",
    "            totalWords.append(word)\n",
    "\n",
    "wordfreqdist = nltk.FreqDist(totalWords)\n",
    "mostcommon = wordfreqdist.most_common(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7888b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreqdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostcommon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanedSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b816b51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wc = WordCloud().generate(CleanedSentences)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wc, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = np.sort(df['Category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63a23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a085fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_categories = [df[df['Category'] == Category].loc[:, ['Absolute_Clean_Resumes', 'Category']] for Category in categories ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02780808",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec969a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Category'].value_counts().sort_index().plot(kind='bar', figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81247f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcloud(df):\n",
    "    txt = ' '.join(txt for txt in df['Absolute_Clean_Resumes'])\n",
    "    wordcloud = WordCloud(height=2000, width=4000, colormap=WORDCLOUD_COLOR_MAP).generate(txt)\n",
    "    \n",
    "    return wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9993f05a",
   "metadata": {},
   "source": [
    "plot_palette = 'tableau-colorblind10'\n",
    "WORDCLOUD_COLOR_MAP = 'tab10_r'\n",
    "plt.style.use(plot_palette)\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(40, 28))\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    wc = wordcloud(data_categories[i])\n",
    "    \n",
    "    plt.subplot(5,5, i+1).set_title(category)\n",
    "    plt.imshow(wc)\n",
    "    plt.axis('off')\n",
    "    plt.plot()\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcea357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod =['Category']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    df[i] = le.fit_transform(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59400578",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2ac201",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Category'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a4c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.xticks()\n",
    "sns.countplot(y='Category', data=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d982783",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetCounts = df['Category'].value_counts().reset_index()['Category']\n",
    "targetLabels = df['Category'].value_counts().reset_index()['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f603033",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50afd817",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ba942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "plt.figure(1,figsize=(20,20))\n",
    "the_grid = GridSpec(2,2)\n",
    "plt.subplot(the_grid[0,1], aspect=1, title='Category Distribution')\n",
    "source_pie = plt.pie(targetCounts, labels = targetLabels, autopct='%1.1f%%', shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d20fa34",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3f5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "requiredText = df['Absolute_Clean_Resumes'].values\n",
    "requiredTarget = df['Category'].values\n",
    "\n",
    "word_vectorizer = TfidfVectorizer(sublinear_tf=True, stop_words='english')\n",
    "word_vectorizer.fit(requiredText)\n",
    "WordFeatures = word_vectorizer.transform(requiredText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e26a170",
   "metadata": {},
   "outputs": [],
   "source": [
    "requiredTarget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dc0075",
   "metadata": {},
   "source": [
    "# spliting the data train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b10fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(WordFeatures, requiredTarget, random_state=12, test_size=0.20, stratify = requiredTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c7456",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f5b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, confusion_matrix, recall_score, accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6837c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ec0fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e98a6",
   "metadata": {},
   "source": [
    "# Support Vector Machine Classifier(SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cb2ddf",
   "metadata": {},
   "source": [
    "Linear Classifier\n",
    "\n",
    "Linear Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8377cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear', C = 1.0)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff838f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = clf.predict(X_train)\n",
    "Y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e394940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = clf.predict(X_test)\n",
    "Y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac903fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Accuracy_1 =accuracy_score(y_train,Y_pred_train)\n",
    "train_Accuracy_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1be690",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Accuracy_1 =accuracy_score(y_test,Y_pred_test)\n",
    "test_Accuracy_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6109000",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647450b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6757197e",
   "metadata": {},
   "source": [
    "Non Linear classifier\n",
    "\n",
    "ploynomial function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f973af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='poly', degree=2)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a73d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = clf.predict(X_train)\n",
    "Y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d39e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = clf.predict(X_test)\n",
    "Y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a4098",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Accuracy_1 =accuracy_score(y_train,Y_pred_train)\n",
    "train_Accuracy_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a5cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Accuracy_1 =accuracy_score(y_test,Y_pred_test)\n",
    "test_Accuracy_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aeeb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd931b7b",
   "metadata": {},
   "source": [
    "Radial kasis function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf', gamma=1)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c539ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = clf.predict(X_train)\n",
    "Y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423464c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = clf.predict(X_test)\n",
    "Y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Accuracy_1 =accuracy_score(y_train,Y_pred_train)\n",
    "train_Accuracy_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Accuracy_1 =accuracy_score(y_test,Y_pred_test)\n",
    "test_Accuracy_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa16402",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_cm1 = confusion_matrix(y_train, Y_pred_train)\n",
    "Train_cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655beb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cm1 = confusion_matrix(y_test, Y_pred_test)\n",
    "test_cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4a3acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(Train_cm1,annot=True)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2663e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(test_cm1,annot=True)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b5175",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e05f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_1 = round(accuracy_score(y_test,Y_pred_test),4)\n",
    "precision_1 = round(precision_score(y_test,Y_pred_test,average='macro'),4)\n",
    "recall_1 = round(recall_score(y_test,Y_pred_test,average='macro'),4)\n",
    "f1_1 = round(f1_score(y_test,Y_pred_test,average='macro'),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00279cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy Score  : ', accuracy_1)\n",
    "print('Precision Score : ', precision_1)\n",
    "print('Recall Score    : ', recall_1)\n",
    "print('f1-Score        : ', f1_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08d70c9",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca1d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10, p=2)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ec32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = knn.predict(X_train)\n",
    "Y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8db98",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = knn.predict(X_test)\n",
    "Y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52baa1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Accuracy_2 = accuracy_score(y_train,Y_pred_train).round(3)\n",
    "train_Accuracy_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103c4b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Accuracy_2 = accuracy_score(y_test,Y_pred_test).round(3)\n",
    "test_Accuracy_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bec73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cm2 = confusion_matrix(y_train,Y_pred_train)\n",
    "train_cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9edb73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cm2 = confusion_matrix(y_test,Y_pred_test)\n",
    "test_cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee92931",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_cm2,annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46cf134",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(test_cm2,annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc66289",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4987ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_2 = round(accuracy_score(y_test,Y_pred_test),4)\n",
    "precision_2 = round(precision_score(y_test,Y_pred_test,average = 'macro'),4)\n",
    "recall_2 = round(recall_score(y_test,Y_pred_test, average = 'macro'),4)\n",
    "f1_2 = round(f1_score(y_test,Y_pred_test, average = 'macro'),4)\n",
    "\n",
    "print('Accuracy Score  : ', accuracy_2)\n",
    "print('Precision Score : ', precision_2)\n",
    "print('Recall Score    : ', recall_2)\n",
    "print('f1-Score        : ', f1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e09fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "456d2c44",
   "metadata": {},
   "source": [
    "# Naive-Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = MultinomialNB()\n",
    "NB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55917acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = NB.predict(X_train)\n",
    "Y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658703ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = NB.predict(X_test)\n",
    "Y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099084a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Accuracy_3 = accuracy_score(y_train, Y_pred_train)\n",
    "train_Accuracy_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be8b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Accuracy_3 = accuracy_score(y_test, Y_pred_test)\n",
    "test_Accuracy_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faff0194",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cm3 = confusion_matrix(y_train, Y_pred_train)\n",
    "train_cm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5449c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cm3 = confusion_matrix(y_test, Y_pred_test)\n",
    "test_cm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_cm3,annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230db7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(test_cm3,annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e71073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8881d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3140bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = NB.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078832b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225ffe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_3 = round(accuracy_score(y_test,Y_pred_test),4)\n",
    "precision_3 = round(precision_score(y_test,Y_pred_test,average = 'macro'),4)\n",
    "recall_3 = round(recall_score(y_test,Y_pred_test, average = 'macro'),4)\n",
    "f1_3 = round(f1_score(y_test,Y_pred_test, average = 'macro'),4)\n",
    "\n",
    "print('Accuracy Score  : ', accuracy_3)\n",
    "print('Precision Score : ', precision_3)\n",
    "print('Recall Score    : ', recall_3)\n",
    "print('f1-Score        : ', f1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4245099b",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5637a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier(max_depth=2)\n",
    "DTC.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7906fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = DTC.predict(X_train)\n",
    "Y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a64484",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = DTC.predict(X_test)\n",
    "Y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a08198",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC.tree_.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ca1dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC.tree_.node_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5163a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Accuracy_4 = accuracy_score(y_train, Y_pred_train)\n",
    "train_Accuracy_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ea7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Accuracy_4 = accuracy_score(y_test, Y_pred_test)\n",
    "test_Accuracy_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95aaf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cm4 = confusion_matrix(y_train, Y_pred_train)\n",
    "train_cm4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7386b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cm4 = confusion_matrix(y_test, Y_pred_test)\n",
    "test_cm4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_cm4,annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b506dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(test_cm4,annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a5aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66479293",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_4 = round(accuracy_score(y_test,Y_pred_test),4)\n",
    "precision_4 = round(precision_score(y_test,Y_pred_test,average = 'macro'),4)\n",
    "recall_4 = round(recall_score(y_test,Y_pred_test, average = 'macro'),4)\n",
    "f1_4 = round(f1_score(y_test,Y_pred_test, average = 'macro'),4)\n",
    "\n",
    "print('Accuracy Score  : ', accuracy_4)\n",
    "print('Precision Score : ', precision_4)\n",
    "print('Recall Score    : ', recall_4)\n",
    "print('f1-Score        : ', f1_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8f4412",
   "metadata": {},
   "source": [
    "# Random Forest Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c063ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(n_estimators=250,max_features=0.8,max_depth=2)\n",
    "RFC.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aafbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = RFC.predict(X_train)\n",
    "Y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0ff524",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = RFC.predict(X_test)\n",
    "Y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853734d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Accuracy_5 = accuracy_score(y_train,Y_pred_train)\n",
    "train_Accuracy_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d385c40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Accuracy_5 = accuracy_score(y_test,Y_pred_test)\n",
    "test_Accuracy_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd74c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cm5 = confusion_matrix(y_train, Y_pred_train)\n",
    "train_cm5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c7ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cm5 = confusion_matrix(y_test, Y_pred_test)\n",
    "test_cm5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e91c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_cm5,annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf86f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(test_cm5,annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048e18af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7966426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_5 = round(accuracy_score(y_test,Y_pred_test),4)\n",
    "precision_5 = round(precision_score(y_test,Y_pred_test,average = 'macro'),4)\n",
    "recall_5 = round(recall_score(y_test,Y_pred_test, average = 'macro'),4)\n",
    "f1_5 = round(f1_score(y_test,Y_pred_test, average = 'macro'),4)\n",
    "\n",
    "print('Accuracy Score  : ', accuracy_5)\n",
    "print('Precision Score : ', precision_5)\n",
    "print('Recall Score    : ', recall_5)\n",
    "print('f1-Score        : ', f1_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68748742",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be78ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost = AdaBoostClassifier(n_estimators=100,random_state=0,learning_rate=0.0001)\n",
    "adaboost.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e7f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = adaboost.predict(X_train)\n",
    "Y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff2389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = adaboost.predict(X_test)\n",
    "Y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a7523",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Accuracy_6 = accuracy_score(y_train,Y_pred_train)\n",
    "train_Accuracy_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f507af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Accuracy_6 = accuracy_score(y_test,Y_pred_test)\n",
    "test_Accuracy_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b84a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cm6 = confusion_matrix(y_train,Y_pred_train)\n",
    "train_cm6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad17ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cm6 = confusion_matrix(y_test,Y_pred_test)\n",
    "test_cm6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028eb651",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_cm6,annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad49722",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(test_cm6,annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba726be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d73f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_6 = round(accuracy_score(y_test,Y_pred_test),4)\n",
    "precision_6 = round(precision_score(y_test,Y_pred_test,average = 'macro'),4)\n",
    "recall_6 = round(recall_score(y_test,Y_pred_test, average = 'macro'),4)\n",
    "f1_6 = round(f1_score(y_test,Y_pred_test, average = 'macro'),4)\n",
    "\n",
    "print('Accuracy Score  : ', accuracy_6)\n",
    "print('Precision Score : ', precision_6)\n",
    "print('Recall Score    : ', recall_6)\n",
    "print('f1-Score        : ', f1_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cfcf11",
   "metadata": {},
   "source": [
    "# GradientBoosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f348e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gboost = GradientBoostingClassifier(n_estimators=100, learning_rate=0.001,max_depth=2, random_state=0)\n",
    "Gboost.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db35fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = Gboost.predict(X_train)\n",
    "Y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85a574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = Gboost.predict(X_test)\n",
    "Y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f1e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Accuracy_7 = accuracy_score(y_train,Y_pred_train)\n",
    "train_Accuracy_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a2d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Accuracy_7 = accuracy_score(y_test,Y_pred_test)\n",
    "test_Accuracy_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a597eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cm7 = confusion_matrix(y_train,Y_pred_train)\n",
    "train_cm7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c434e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cm7 = confusion_matrix(y_test,Y_pred_test)\n",
    "test_cm7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeee0f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_cm7,annot=True)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0014d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(test_cm7,annot=True)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed046fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb60090",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_7 = round(accuracy_score(y_test,Y_pred_test),4)\n",
    "precision_7 = round(precision_score(y_test,Y_pred_test,average = 'macro'),4)\n",
    "recall_7 = round(recall_score(y_test,Y_pred_test, average = 'macro'),4)\n",
    "f1_7 = round(f1_score(y_test,Y_pred_test, average = 'macro'),4)\n",
    "\n",
    "print('Accuracy Score  : ', accuracy_7)\n",
    "print('Precision Score : ', precision_7)\n",
    "print('Recall Score    : ', recall_7)\n",
    "print('f1-Score        : ', f1_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1952376c",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c32593",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGboost = XGBClassifier(n_estimators=200, learning_rate=0.09,max_depth=3, random_state=0)\n",
    "XGboost.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7f2636",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = XGboost.predict(X_train)\n",
    "Y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49623e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = XGboost.predict(X_test)\n",
    "Y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b8133",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Accuracy_8 = accuracy_score(y_train,Y_pred_train)\n",
    "train_Accuracy_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Accuracy_8 = accuracy_score(y_test,Y_pred_test)\n",
    "test_Accuracy_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ebf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cm8 = confusion_matrix(y_train,Y_pred_train)\n",
    "train_cm8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cm8 = confusion_matrix(y_test,Y_pred_test)\n",
    "test_cm8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb10d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_cm8,annot=True)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel('truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1633d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(test_cm8,annot=True)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel('truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f3fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88575f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_8 = round(accuracy_score(y_test,Y_pred_test),4)\n",
    "precision_8 = round(precision_score(y_test,Y_pred_test,average = 'macro'),4)\n",
    "recall_8 = round(recall_score(y_test,Y_pred_test, average = 'macro'),4)\n",
    "f1_8 = round(f1_score(y_test,Y_pred_test, average = 'macro'),4)\n",
    "\n",
    "print('Accuracy Score  : ', accuracy_8)\n",
    "print('Precision Score : ', precision_8)\n",
    "print('Recall Score    : ', recall_8)\n",
    "print('f1-Score        : ', f1_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70804f49",
   "metadata": {},
   "source": [
    "# LGBM-Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee277b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGboost = LGBMClassifier()\n",
    "LGboost.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d5da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = LGboost.predict(X_train)\n",
    "Y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e83a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = LGboost.predict(X_test)\n",
    "Y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716ddae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Accuracy_9 = accuracy_score(y_train, Y_pred_train)\n",
    "train_Accuracy_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f15c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Accuracy_9 = accuracy_score(y_test, Y_pred_test)\n",
    "test_Accuracy_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e422d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cm9 = confusion_matrix(y_train,Y_pred_train)\n",
    "train_cm9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54070f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cm9 = confusion_matrix(y_test,Y_pred_test)\n",
    "test_cm9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d6ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_cm9,annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2953eebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(test_cm9,annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd4e837",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f1d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_9 = round(accuracy_score(y_test,Y_pred_test),4)\n",
    "precision_9 = round(precision_score(y_test,Y_pred_test,average = 'macro'),4)\n",
    "recall_9 = round(recall_score(y_test,Y_pred_test, average = 'macro'),4)\n",
    "f1_9 = round(f1_score(y_test,Y_pred_test, average = 'macro'),4)\n",
    "\n",
    "print('Accuracy Score  : ', accuracy_9)\n",
    "print('Precision Score : ', precision_9)\n",
    "print('Recall Score    : ', recall_9)\n",
    "print('f1-Score        : ', f1_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {'Classifier' : ['SVM Classifier','K-Nearest Neighbourhood Classifier','Naive-Bayes Classifier','Decision Tree Classifier','Random Forest Classifier','AdaBoost Classifier', 'Gradient Boosting Classifier', 'Xtreme Gradient Boosting Classifier', 'Light Gradient Boosting Classifier'], \n",
    "         'Training_Accuracy' : [train_Accuracy_1, train_Accuracy_2, train_Accuracy_3, train_Accuracy_4, train_Accuracy_5, train_Accuracy_6, train_Accuracy_7, train_Accuracy_8, train_Accuracy_9], \n",
    "         'Testing_Accuracy' : [test_Accuracy_1, test_Accuracy_2, test_Accuracy_3,test_Accuracy_4,test_Accuracy_5,test_Accuracy_6, test_Accuracy_7, test_Accuracy_8, test_Accuracy_9], \n",
    "         'Precision Score' : [precision_1, precision_2, precision_3, precision_4, precision_5, precision_6, precision_7, precision_8, precision_9], \n",
    "         'Recall Score' : [recall_1, recall_2, recall_3, recall_4, recall_5, recall_6, recall_7, recall_8, recall_9], \n",
    "         'F1_Score' : [f1_1, f1_2, f1_3, f1_4, f1_5, f1_6, f1_7, f1_8, f1_9]}\n",
    "table = pd.DataFrame(table)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6598dd1",
   "metadata": {},
   "source": [
    "# convolutional neural networks Model(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5595d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(WordFeatures.shape[1], 1)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(units=64, activation='relu'))\n",
    "cnn_model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b2609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620b0bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2D = X_train.toarray().reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "cnn_model.fit(X_train_2D, y_train, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26fd3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test data\n",
    "X_test_2D = X_test.toarray().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "cnn_pred = cnn_model.predict(X_test_2D)\n",
    "\n",
    "# Print example predictions\n",
    "for i in range(10):\n",
    "    print('True label: {}, Predicted label: {}'.format(y_test[i], cnn_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ffa291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "# Calculate performance metrics\n",
    "accuracy_cnn = accuracy_score(y_test, cnn_pred)\n",
    "precision_cnn = precision_score(y_test, cnn_pred, average='weighted')\n",
    "recall_cnn = recall_score(y_test, cnn_pred, average='weighted')\n",
    "f1_cnn = f1_score(y_test, cnn_pred, average='weighted')\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Accuracy:\", accuracy_cnn)\n",
    "print(\"Precision:\", precision_cnn)\n",
    "print(\"Recall:\", recall_cnn)\n",
    "print(\"F1 score:\", f1_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeddb3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# assume that the trained model is stored in a variable called \"model\"\n",
    "with open('RFC.pickle', 'wb') as f:\n",
    "    pickle.dump(RFC, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2764e745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
